{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person : hari mausaji\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "(29, 30000)\n",
      "Data Successfully save at ./DATAlr/hari mausaji.npy\n"
     ]
    }
   ],
   "source": [
    "#write a python script which captures images from your webcam videostream\n",
    "#extract all the faces from the image frame(using haarcascade)\n",
    "#stores the face information into numpy arrays\n",
    "\n",
    "#1. Read and show video stream,capture images\n",
    "#2.detect faces and show biunding box\n",
    "#3.flatten the largest face image and save it in a numpy array\n",
    "#4.repeat the above for multiple people to generate training data\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "skip = 0\n",
    "face_data = []\n",
    "dataset_path = './DATAlr/'\n",
    "file_name = input(\"Enter the name of the person : \")\n",
    "while True:\n",
    "\tret,frame = cap.read()\n",
    "\n",
    "\tif ret==False:\n",
    "\t\tcontinue\n",
    "\n",
    "\tgray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\n",
    "\tfaces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "\tif len(faces)==0:\n",
    "\t\tcontinue\n",
    "\t\t\n",
    "\tfaces = sorted(faces,key=lambda f:f[2]*f[3])\n",
    "\n",
    "\t# Pick the last face (because it is the largest face acc to area(f[2]*f[3]))\n",
    "\tfor face in faces[-1:]:\n",
    "\t\tx,y,w,h = face\n",
    "\t\tcv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "\t\t#Extract (Crop out the required face) : Region of Interest\n",
    "\t\toffset = 10\n",
    "\t\tface_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "\t\tface_section = cv2.resize(face_section,(100,100))\n",
    "\n",
    "\t\tskip += 1\n",
    "\t\tif skip%10==0:\n",
    "\t\t\tface_data.append(face_section)\n",
    "\t\t\tprint(len(face_data))\n",
    "\n",
    "\n",
    "\tcv2.imshow(\"Frame\",frame)\n",
    "\tcv2.imshow(\"Face Section\",face_section)\n",
    "\n",
    "\tkey_pressed = cv2.waitKey(1) & 0xFF\n",
    "\tif key_pressed == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "# Convert our face list array into a numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "# Save this data into file system\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data Successfully save at \"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
